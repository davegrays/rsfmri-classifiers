{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, GRU, Dropout, BatchNormalization, Conv1D, AvgPool1D, Flatten\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import L1L2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('data/abide/postprocessed_timeseries.npy')\n",
    "Xcorr = np.load('data/abide/postprocessed_corrmats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary inputs\n",
    "df = pd.read_csv('data/abide/postprocessed_metadata.csv')\n",
    "age_and_sex_df_centered = df[['AGE_AT_SCAN', 'SEX']] - [15, 1.5]\n",
    "age_and_sex_df_normed = age_and_sex_df_centered / [10, 1]\n",
    "offline_train = np.array(age_and_sex_df_normed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "Y = np.array(df['DX_GROUP'] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741, 295, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741, 19900)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcorr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(741, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offline_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model params for LSTM (some common to linear model too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "class ModelSettings:\n",
    "    val_size = 0.1\n",
    "    hidden_dim = 32\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    batch_size = 16 # 16 for LSTM, 741 for linear (i.e. just use batch GD)\n",
    "    epochs = 35 # 35 for LSTM, 250 for linear\n",
    "    early_stop = EarlyStopping(monitor='loss', patience=10, verbose=1)\n",
    "    loss = 'binary_crossentropy'\n",
    "    metrics = ['accuracy']\n",
    "    final_activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define cross validation + aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "def train_model(X, Y, model_setup_func, kfold=True):\n",
    "    if kfold:\n",
    "        # define 10-fold cross validation test harness\n",
    "        my_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "        cvscores = []\n",
    "        for train, test in my_kfold.split(X, Y):\n",
    "            model = model_setup_func(X, kfold)\n",
    "            model.fit(X[train], Y[train], epochs=ModelSettings.epochs, batch_size=ModelSettings.batch_size,\n",
    "                      validation_split=ModelSettings.val_size, verbose=0)\n",
    "            # evaluate the model\n",
    "            scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "            print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "            cvscores.append(scores[1] * 100)\n",
    "        print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "        \n",
    "    else:\n",
    "        model = model_setup_func(X, kfold)\n",
    "        model.fit(X, Y, epochs=ModelSettings.epochs, batch_size=ModelSettings.batch_size,\n",
    "                  validation_split=ModelSettings.val_size, callbacks=[ModelSettings.early_stop])\n",
    "    return model, cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define linear model setup with corrmats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_linear_model(Xcorr, kfold=True):\n",
    "    model = Sequential()\n",
    "    #model.add(Dropout(0.5, input_shape=Xcorr.shape[1:]))\n",
    "    model.add(Dense(1, kernel_regularizer=L1L2(0.02, 0.02), bias_regularizer=L1L2(0.02, 0.02), \n",
    "                    input_shape=Xcorr.shape[1:], activation=ModelSettings.final_activation))\n",
    "    model.compile(loss=ModelSettings.loss, optimizer=keras.optimizers.Adam(lr=0.0001), metrics=ModelSettings.metrics)\n",
    "    if not kfold:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define LSTM setup with timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_lstm(X, kfold=True):\n",
    "    model = Sequential()\n",
    "    reg = L1L2(0.001, 0.001)\n",
    "    model.add(LSTM(ModelSettings.hidden_dim, input_shape=X.shape[1:], dropout=0.5, recurrent_dropout=0.5, \n",
    "                   kernel_regularizer=reg, recurrent_regularizer=reg, bias_regularizer=reg))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation=ModelSettings.final_activation))\n",
    "    model.compile(loss=ModelSettings.loss, optimizer=ModelSettings.optimizer, metrics=ModelSettings.metrics)\n",
    "    if not kfold:\n",
    "        print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model with 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "acc: 66.67%\n",
      "acc: 73.33%\n",
      "acc: 55.41%\n",
      "acc: 56.76%\n",
      "acc: 55.41%\n",
      "acc: 54.05%\n",
      "acc: 55.41%\n",
      "acc: 58.11%\n",
      "acc: 58.11%\n",
      "acc: 56.16%\n",
      "58.94% (+/- 5.85%)\n"
     ]
    }
   ],
   "source": [
    "model_lin, cvscores_lin = train_model(Xcorr, Y, setup_linear_model, kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with 10-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "acc: 58.67%\n",
      "acc: 57.33%\n",
      "acc: 50.00%\n",
      "acc: 47.30%\n",
      "acc: 47.30%\n",
      "acc: 50.00%\n",
      "acc: 60.81%\n",
      "acc: 52.70%\n",
      "acc: 55.41%\n",
      "acc: 54.79%\n",
      "53.43% (+/- 4.50%)\n"
     ]
    }
   ],
   "source": [
    "model, cvscores = train_model(X, Y, setup_lstm, kfold=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get top 10 most salient features of autism dx's in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/experiencor/deep-viz-keras\n",
    "from guided_backprop import GuidedBackprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/guided_backprop_ckpt\n"
     ]
    }
   ],
   "source": [
    "guided_bprop = GuidedBackprop(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autism is the 0 class, therefore you need to find the most negative derivatives for those samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autX = X[Y == 0, :, :]\n",
    "mask = np.zeros((autX.shape[1:]))\n",
    "for i in range(autX.shape[0]):\n",
    "    mask += guided_bprop.get_mask(autX[i, :, :])\n",
    "\n",
    "mask /= autX.shape[0]\n",
    "mask_1d = mask.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiondf = pd.read_csv('CC200_ROI_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[\"Cingulum_Ant_R\": 0.44][\"Cingulum_Ant_L\": 0.40]',\n",
       "       '[\"Cingulum_Mid_L\": 0.32][\"Cingulum_Mid_R\": 0.22][\"Cingulum_Ant_L\": 0.21][\"Cingulum_Ant_R\": 0.20]',\n",
       "       '[\"Cerebelum_Crus1_L\": 0.75][\"Cerebelum_6_L\": 0.18]',\n",
       "       '[\"Frontal_Mid_L\": 0.72][\"Frontal_Sup_L\": 0.28]',\n",
       "       '[\"Frontal_Sup_R\": 0.41][\"Supp_Motor_Area_R\": 0.41][\"Frontal_Sup_Medial_R\": 0.18]',\n",
       "       '[\"Precuneus_L\": 0.46][\"Precuneus_R\": 0.36]',\n",
       "       '[\"Frontal_Sup_R\": 0.50][\"Frontal_Sup_Medial_R\": 0.42]',\n",
       "       '[\"Fusiform_R\": 0.54][\"Hippocampus_R\": 0.21][\"ParaHippocampal_R\": 0.19]',\n",
       "       '[\"Cingulum_Ant_L\": 0.66][\"Frontal_Sup_Medial_L\": 0.28]',\n",
       "       '[\"Fusiform_L\": 0.45][\"Temporal_Inf_L\": 0.21][\"ParaHippocampal_L\": 0.13]'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regiondf.iloc[mask_1d.argsort()[:10]]['AAL'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### renamed\n",
    "ACC bilateral\n",
    "MCC bilateral\n",
    "Cerebellum left\n",
    "Mid Frontal left\n",
    "Sup Frontal left\n",
    "Precuneus bilateral\n",
    "Sup Frontal bilateral\n",
    "Fusiform left\n",
    "ACC left\n",
    "Fusiform right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM with aux inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use functional api to create LSTM and merge output with auxiliary input\n",
    "# TIME_SERIES --->  LSTM --->|\n",
    "#                            MERGED ---> | --> diagnosis\n",
    "#     PATIENT_FEATURES ---> |\n",
    "\n",
    "reg = L1L2(0.001, 0.001)\n",
    "channel1 = keras.layers.Input(shape=X.shape[1:], name='channel1')\n",
    "\n",
    "model_gru = LSTM(ModelSettings.hidden_dim, dropout=0.5, recurrent_dropout=0.5,\n",
    "                kernel_regularizer=reg, recurrent_regularizer=reg, bias_regularizer=reg)(channel1)\n",
    "\n",
    "# At this point, we feed into the model our auxiliary input data by concatenating it with the GRU output\n",
    "auxiliary_input = keras.layers.Input(shape=(offline_train.shape[1],), name='aux_input')\n",
    "x = keras.layers.concatenate([model_gru, auxiliary_input])\n",
    "x = Dropout(0.5)(x)  \n",
    "\n",
    "# We stack a another layer on top\n",
    "#x = Dense(ModelSettings.hidden_dim, activation='sigmoid')(x)\n",
    "#x = Dropout(0.5)(x) \n",
    "\n",
    "# And finally we add the classification layer\n",
    "main_output = Dense(1, activation=ModelSettings.final_activation, name='main_output')(x)\n",
    "\n",
    "# now we compile and run\n",
    "deep = keras.models.Model(inputs=[channel1, auxiliary_input], outputs=[main_output])\n",
    "deep.compile(loss=ModelSettings.loss, optimizer=ModelSettings.optimizer, metrics=ModelSettings.metrics)\n",
    "print(deep.summary())\n",
    "deep.fit([X, offline_train], Y,\n",
    "         epochs=ModelSettings.epochs, batch_size=ModelSettings.batch_size,\n",
    "         validation_split=ModelSettings.val_size, callbacks=[ModelSettings.early_stop])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### temporal CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg = L1L2(0.0001, 0.0001)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=X.shape[1:],\n",
    "                kernel_regularizer=reg, bias_regularizer=reg))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AvgPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AvgPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(AvgPool1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(AvgPool1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#model.add(Dense(16, activation='relu', kernel_regularizer=reg, bias_regularizer=reg))\n",
    "model.add(Dense(1, activation=ModelSettings.final_activation))\n",
    "model.compile(loss=ModelSettings.loss, optimizer=keras.optimizers.Adam(lr=0.002), metrics=ModelSettings.metrics)\n",
    "print(model.summary())\n",
    "model.fit(X, Y, epochs=ModelSettings.epochs, batch_size=ModelSettings.batch_size,\n",
    "         validation_split=ModelSettings.val_size, callbacks=[ModelSettings.early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
